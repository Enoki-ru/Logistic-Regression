{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добрый вечер ребята\n",
    "Сегодня я хочу вспомнить все основные аспекты, которые я прошел ранее, а заодно пройдусь по новой теории, на которую раньше не обращал внимание.\n",
    "Опустим Линейную регрессию, ей мы и так очень много занимались. Кроме линейной, существует еще логистическая регрессия, и сегодня мы изучим именно ее.\n",
    "\n",
    "---\n",
    "\n",
    "Для начала загрузим все библиотеки, которые будем использовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0           M        17.99         10.38          122.80     1001.0   \n",
       "1           M        20.57         17.77          132.90     1326.0   \n",
       "2           M        19.69         21.25          130.00     1203.0   \n",
       "3           M        11.42         20.38           77.58      386.1   \n",
       "4           M        20.29         14.34          135.10     1297.0   \n",
       "..        ...          ...           ...             ...        ...   \n",
       "564         M        21.56         22.39          142.00     1479.0   \n",
       "565         M        20.13         28.25          131.20     1261.0   \n",
       "566         M        16.60         28.08          108.30      858.1   \n",
       "567         M        20.60         29.33          140.10     1265.0   \n",
       "568         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.2419  ...        25.380          17.33           184.60   \n",
       "1           0.1812  ...        24.990          23.41           158.80   \n",
       "2           0.2069  ...        23.570          25.53           152.50   \n",
       "3           0.2597  ...        14.910          26.50            98.87   \n",
       "4           0.1809  ...        22.540          16.67           152.20   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Прочитаем датасет, который я нашел в недрах интернета\n",
    "data=pd.read_csv('data.csv')\n",
    "#Давайте удалим пустой столбец, раз уж он нам не нужен\n",
    "data.drop(['Unnamed: 32','id'], axis=1, inplace=True) #inplace=True позволяет изменить оригинал датасета, если бы мы не написали, то изменялась бы копия. Поэтому с этим параметром можно не писать data=data.drop...\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* diagnosis - \n",
      "* radius_mean - \n",
      "* texture_mean - \n",
      "* perimeter_mean - \n",
      "* area_mean - \n",
      "* smoothness_mean - \n",
      "* compactness_mean - \n",
      "* concavity_mean - \n",
      "* concave points_mean - \n",
      "* symmetry_mean - \n",
      "* fractal_dimension_mean - \n",
      "* radius_se - \n",
      "* texture_se - \n",
      "* perimeter_se - \n",
      "* area_se - \n",
      "* smoothness_se - \n",
      "* compactness_se - \n",
      "* concavity_se - \n",
      "* concave points_se - \n",
      "* symmetry_se - \n",
      "* fractal_dimension_se - \n",
      "* radius_worst - \n",
      "* texture_worst - \n",
      "* perimeter_worst - \n",
      "* area_worst - \n",
      "* smoothness_worst - \n",
      "* compactness_worst - \n",
      "* concavity_worst - \n",
      "* concave points_worst - \n",
      "* symmetry_worst - \n",
      "* fractal_dimension_worst - \n"
     ]
    }
   ],
   "source": [
    "# Напишем небольшой код чтобы быстро скопировать названия столбцов в нужном нам формате\n",
    "i=0\n",
    "for name in data.columns:\n",
    "    print(f\"* {name} - \")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте рассмотрим эту таблицу и вообще поймем, каике столбцы что обозначают.\n",
    "* id - id клиента\n",
    "* diagnosis - Диагноз (M = злокачественный, B = доброкачественный)\n",
    "* radius_mean - радиус (среднее значение расстояний от центра до точек по периметру)\n",
    "* texture_mean - текстура (стандартное отклонение значений шкалы серого)\n",
    "* perimeter_mean - периметр\n",
    "* area_mean - область\n",
    "* smoothness_mean - плавность (локальное изменение длины радиуса)\n",
    "* compactness_mean - компактность (периметр^2 / площадь - 1,0)\n",
    "* concavity_mean - вогнутость (выраженность вогнутых участков контура)\n",
    "* concave points_mean - точки вогнутости (количество вогнутых участков контура)\n",
    "* symmetry_mean - симметрия\n",
    "* fractal_dimension_mean - фрактальное измерение (\"приближение береговой линии\" - 1)\n",
    "* radius_se - стандартная ошибка для среднего значения расстояний от центра до точек по периметру\n",
    "* texture_se - стандартная ошибка для стандартного отклонения значений шкалы серого\n",
    "* perimeter_se - стандартная ошибка для периметра\n",
    "* area_se - *по аналогии*\n",
    "* smoothness_se - \n",
    "* compactness_se - \n",
    "* concavity_se - \n",
    "* concave points_se - \n",
    "* symmetry_se - \n",
    "* fractal_dimension_se - \n",
    "* radius_worst - \"наихудшее\" или наибольшее среднее значение для среднего расстояния от центра до точек по периметру\n",
    "* texture_worst - \"наихудшее\" или наибольшее среднее значение для стандартного отклонения значений по шкале серого\n",
    "* perimeter_worst - *по аналогии*\n",
    "* area_worst - \n",
    "* smoothness_worst - \"наихудшее\" или наибольшее среднее значение для локального изменения длин радиусов\n",
    "* compactness_worst - *по аналогии*\n",
    "* concavity_worst - \n",
    "* concave points_worst - \n",
    "* symmetry_worst - \n",
    "* fractal_dimension_worst - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      M\n",
      "1      M\n",
      "2      M\n",
      "3      M\n",
      "4      M\n",
      "      ..\n",
      "564    M\n",
      "565    M\n",
      "566    M\n",
      "567    M\n",
      "568    B\n",
      "Name: diagnosis, Length: 569, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "564    1\n",
       "565    1\n",
       "566    1\n",
       "567    1\n",
       "568    0\n",
       "Name: diagnosis, Length: 569, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.diagnosis)\n",
    "data.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis]\n",
    "data.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1\n",
      " 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1\n",
      " 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0\n",
      " 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0\n",
      " 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1\n",
      " 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "#Теперь давйте разделим наши данные для более удобной обработки\n",
    "print(data.diagnosis.values) #позволяет из датафрейма перейти в список\n",
    "y=data.diagnosis.values\n",
    "#y=data.diagnosis\n",
    "x_data=data.drop(['diagnosis'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-Max Нормализация\n",
    "Существует метод, который изменяет масштаб значений, чтобы они находились в диапазоне от 0 до 1. Кроме того, данные в конечном итоге имеют меньшие стандартные отклонения, что может подавить эффект выбросов.\n",
    "Формула Min-Man Нормализации выглядит следующим образом:\n",
    "$$\\begin{array}{l}\n",
    "{x_{i,norm}} = \\frac{{{x_i} - {x_{\\min }}}}{{{x_{\\max }} - {x_{\\min }}}}\\\\\n",
    "\n",
    "\\end{array}$$\n",
    "${x_i}\\, - \\ i-й \\ непреобразованный \\ элемент\\\\\n",
    "{x_{\\min }}\\, - \\ наименьший \\ элемент\\\\\n",
    "{x_{\\max }}\\, - \\ наибольший \\ элемент$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius_mean                  6.981000\n",
       "texture_mean                 9.710000\n",
       "perimeter_mean              43.790000\n",
       "area_mean                  143.500000\n",
       "smoothness_mean              0.052630\n",
       "compactness_mean             0.019380\n",
       "concavity_mean               0.000000\n",
       "concave points_mean          0.000000\n",
       "symmetry_mean                0.106000\n",
       "fractal_dimension_mean       0.049960\n",
       "radius_se                    0.111500\n",
       "texture_se                   0.360200\n",
       "perimeter_se                 0.757000\n",
       "area_se                      6.802000\n",
       "smoothness_se                0.001713\n",
       "compactness_se               0.002252\n",
       "concavity_se                 0.000000\n",
       "concave points_se            0.000000\n",
       "symmetry_se                  0.007882\n",
       "fractal_dimension_se         0.000895\n",
       "radius_worst                 7.930000\n",
       "texture_worst               12.020000\n",
       "perimeter_worst             50.410000\n",
       "area_worst                 185.200000\n",
       "smoothness_worst             0.071170\n",
       "compactness_worst            0.027290\n",
       "concavity_worst              0.000000\n",
       "concave points_worst         0.000000\n",
       "symmetry_worst               0.156500\n",
       "fractal_dimension_worst      0.055040\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#функции np.min и np.max вовращают мин и макс значения датафрейма\n",
    "np.min(x_data, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52103744, 0.0226581 , 0.54598853, ..., 0.91202749, 0.59846245,\n",
       "        0.41886396],\n",
       "       [0.64314449, 0.27257355, 0.61578329, ..., 0.63917526, 0.23358959,\n",
       "        0.22287813],\n",
       "       [0.60149557, 0.3902604 , 0.59574321, ..., 0.83505155, 0.40370589,\n",
       "        0.21343303],\n",
       "       ...,\n",
       "       [0.45525108, 0.62123774, 0.44578813, ..., 0.48728522, 0.12872068,\n",
       "        0.1519087 ],\n",
       "       [0.64456434, 0.66351031, 0.66553797, ..., 0.91065292, 0.49714173,\n",
       "        0.45231536],\n",
       "       [0.03686876, 0.50152181, 0.02853984, ..., 0.        , 0.25744136,\n",
       "        0.10068215]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Нормализация\n",
    "x=((x_data-np.min(x_data, axis=0))/(np.max(x_data,axis=0)-np.min(x_data, axis=0))).values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры разделенных массивов\n",
      "x_train: (30, 483)\n",
      "x_test: (30, 86)\n",
      "y_train: (483,)\n",
      "y_test:(86,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.15, random_state=42)\n",
    "x_train=x_train.T\n",
    "x_test=x_test.T\n",
    "y_train=y_train.T\n",
    "y_test=y_test.T\n",
    "print('Размеры разделенных массивов')\n",
    "print(f\"x_train: {x_train.shape}\\nx_test: {x_test.shape}\\ny_train: {y_train.shape}\\ny_test:{y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 1)\n",
      "[[0.01]\n",
      " [0.01]\n",
      " [0.01]\n",
      " ...\n",
      " [0.01]\n",
      " [0.01]\n",
      " [0.01]]\n"
     ]
    }
   ],
   "source": [
    "# В дальнейшем понадобится\n",
    "def initialize_weights_and_bias(dimension):\n",
    "    w = np.full((dimension,1),0.01)\n",
    "    b = 0.0\n",
    "    return w, b\n",
    "\n",
    "a,b=initialize_weights_and_bias(4096)\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Сигмоида\n",
    "# Нужна для решения логистического уравнения, приводит к сглаживанию некоторых значений, и для оценки вероятности событий\n",
    "#z = np.dot(w.T,x_train)+b\n",
    "def sigmoid(z):\n",
    "    y_head = 1/(1+np.exp(-z))\n",
    "    return y_head\n",
    "#y_head = sigmoid(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка работы машинного обучения\n",
    "    Оценить — означает указать количественно, хорошо или плохо сеть решает поставленные ей задачи. Для этого строится функция оценки. Она, как правило, явно зависит от выходных сигналов сети и неявно (через функционирование) — от всех её параметров. Простейший и самый распространённый пример оценки — сумма квадратов расстояний от выходных сигналов сети до их требуемых значений:\n",
    "\n",
    " $$H = \\frac{1}{2} \\cdot \\sum\\limits_r {{{\\left( {Z(r) - {Z^ * }(r)} \\right)}^2}} $$\n",
    " Метод наименьших квадратов далеко не всегда является лучшим выбором оценки. Тщательное конструирование функции оценки позволяет на порядок повысить эффективность обучения сети, а также получать дополнительную информацию — «уровень уверенности» сети в даваемом ответе. Именно поэтому были придуманы другие способы оценки. Мы же воспользуемся градиентным спуском, однако коэффициенты для спуска будут меняться после каждого шага, поэтому вы в любом случае найдем минимум. Единственной проблемой является нахождение ошибочного минимума, который называется просто **локальным** минимумом. \n",
    "\n",
    " Так как у нас будет двоичная классификация (злокачественная или доброкачественная опухоль), то нам нужно будет получить значения в форме вероятностей.\n",
    " Это нужно нам для того, чтобы применить функцию активации. К примеру, если вероятность злокачественной будет >50%, то мы скажем Да, а если <50%, то скажем Нет. \n",
    " Но как это реализовать в масштабах машинного обучения? Нам же нужно, чтобы машина училась на своих же ошибках.\n",
    " Для этого мы будет брать Сигмоиду от наших данных. ![Фото](https://avatars.dzeninfra.ru/get-zen_doc/1368767/pub_60771a76c3445e46f5419930_60771a7b50d6720e3438dbba/scale_2400)\n",
    "\n",
    " Ну и также в случае бинарной классификации(Собака или кошка = 0 или 1) функция Потерь будет иметь вид\n",
    " $$CE =  - \\left( {y\\log (p) + (1 - y)\\log (1 - p)} \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward and backward propagation\n",
    "def forward_backward_propagation(w,b,x_train,y_train):\n",
    "    #forward pass\n",
    "    \n",
    "    z=np.dot(w.T,x_train)+b #Перемножим \n",
    "    # print(x_train.shape)\n",
    "    # print(w.T.shape)\n",
    "    # print(z.shape)\n",
    "    y_head=sigmoid(z)\n",
    "    loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head) #функция потерь\n",
    "    cost = (np.sum(loss))/x_train.shape[1]      # x_train.shape[1]  is for scaling\n",
    "    # backward propagation\n",
    "    derivative_weight = (np.dot(x_train,((y_head-y_train).T)))/x_train.shape[1] # x_train.shape[1]  is for scaling\n",
    "    derivative_bias = np.sum(y_head-y_train)/x_train.shape[1]                 # x_train.shape[1]  is for scaling\n",
    "    gradients = {\"derivative_weight\": derivative_weight,\"derivative_bias\": derivative_bias}\n",
    "    return cost,gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%# Updating(learning) parameters\n",
    "def update(w, b, x_train, y_train, learning_rate,number_of_iterarion):\n",
    "    cost_list = []\n",
    "    cost_list2 = []\n",
    "    index = []\n",
    "    # updating(learning) parameters is number_of_iterarion times\n",
    "    for i in range(number_of_iterarion):\n",
    "        # make forward and backward propagation and find cost and gradients\n",
    "        cost,gradients = forward_backward_propagation(w,b,x_train,y_train)\n",
    "        cost_list.append(cost)\n",
    "        # lets update\n",
    "        w = w - learning_rate * gradients[\"derivative_weight\"]\n",
    "        b = b - learning_rate * gradients[\"derivative_bias\"]\n",
    "        if i % 10 == 0:\n",
    "            cost_list2.append(cost)\n",
    "            index.append(i)\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    # we update(learn) parameters weights and bias\n",
    "    parameters = {\"weight\": w,\"bias\": b}\n",
    "    plt.plot(index,cost_list2)\n",
    "    plt.xticks(index,rotation='vertical')\n",
    "    plt.xlabel(\"Number of Iterarion\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    return parameters, gradients, cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  # prediction\n",
    "def predict(w,b,x_test):\n",
    "    # x_test is a input for forward propagation\n",
    "    z = sigmoid(np.dot(w.T,x_test)+b)\n",
    "    Y_prediction = np.zeros((1,x_test.shape[1]))\n",
    "    # if z is bigger than 0.5, our prediction is sign one (y_head=1),\n",
    "    # if z is smaller than 0.5, our prediction is sign zero (y_head=0),\n",
    "    for i in range(z.shape[1]):\n",
    "        if z[0,i]<= 0.5:\n",
    "            Y_prediction[0,i] = 0\n",
    "        else:\n",
    "            Y_prediction[0,i] = 1\n",
    "\n",
    "    return Y_prediction\n",
    "# predict(parameters[\"weight\"],parameters[\"bias\"],x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.692836\n",
      "Cost after iteration 10: 0.498576\n",
      "Cost after iteration 20: 0.404996\n",
      "Cost after iteration 30: 0.350059\n",
      "Cost after iteration 40: 0.313747\n",
      "Cost after iteration 50: 0.287767\n",
      "Cost after iteration 60: 0.268114\n",
      "Cost after iteration 70: 0.252627\n",
      "Cost after iteration 80: 0.240036\n",
      "Cost after iteration 90: 0.229543\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 94.40993788819875 %\n",
      "test accuracy: 94.18604651162791 %\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "def logistic_regression(x_train, y_train, x_test, y_test, learning_rate ,  num_iterations):\n",
    "    # initialize\n",
    "    dimension =  x_train.shape[0]  # that is 4096\n",
    "    w,b = initialize_weights_and_bias(dimension)\n",
    "    # do not change learning rate\n",
    "    parameters, gradients, cost_list = update(w, b, x_train, y_train, learning_rate,num_iterations)\n",
    "    \n",
    "    y_prediction_test = predict(parameters[\"weight\"],parameters[\"bias\"],x_test)\n",
    "    y_prediction_train = predict(parameters[\"weight\"],parameters[\"bias\"],x_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "    \n",
    "logistic_regression(x_train, y_train, x_test, y_test,learning_rate = 1, num_iterations = 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь сделаем то же самое, но с использованием встроенной функции от sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.9767441860465116 \n",
      "train accuracy: 0.968944099378882 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=150, random_state=51)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=150, random_state=51)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=150, random_state=51)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn\n",
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression(random_state = 51,max_iter= 150)\n",
    "print(f\"test accuracy: {logreg.fit(x_train.T, y_train.T).score(x_test.T, y_test.T)} \")\n",
    "print(f\"train accuracy: {logreg.fit(x_train.T, y_train.T).score(x_train.T, y_train.T)} \")\n",
    "logreg.fit(x_train.T, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Давайте проверим работоспособность машины на каком-нибудь примере.\n",
    "def predicting(test,n):\n",
    "    print('\\n--------------------------------------')\n",
    "    print(f\"Настоящий результат:{y[n]}\")\n",
    "    Prediction=logreg.predict(test)\n",
    "    print(f'Машинный результат:{Prediction}\\n----------------------\\n')\n",
    "    call='не '\n",
    "    call2='доброкачественная'\n",
    "    if Prediction[0]:\n",
    "        call=''\n",
    "        call2='злокачественная'\n",
    "    print(f\"Поздравляем вас, вы {call}больны. Ваша опухоль {call2}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------\n",
      "Настоящий результат:0\n",
      "Машинный результат:[0]\n",
      "----------------------\n",
      "\n",
      "Поздравляем вас, вы не больны. Ваша опухоль доброкачественная!\n",
      "\n",
      "--------------------------------------\n",
      "Настоящий результат:1\n",
      "Машинный результат:[1]\n",
      "----------------------\n",
      "\n",
      "Поздравляем вас, вы больны. Ваша опухоль злокачественная!\n",
      "\n",
      "--------------------------------------\n",
      "Настоящий результат:1\n",
      "Машинный результат:[1]\n",
      "----------------------\n",
      "\n",
      "Поздравляем вас, вы больны. Ваша опухоль злокачественная!\n"
     ]
    }
   ],
   "source": [
    "n=500\n",
    "for n in range(497,500):\n",
    "    test=[x[n]]\n",
    "    predicting(test,n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Недостатки\n",
    "1. Машина может и переобучиться, за этим также нужно следить\n",
    "2. Машина воспринимает данные только в нормализованном виде, а значит, нужно постоянно хранить значения для тренировки (train), потому что иначе при добавлении "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
